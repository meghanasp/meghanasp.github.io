<!-- selenium.html -->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>QA Notes</title>
  <style>
  details {
    background: #f9f9f9;
    border: 1px solid #ccc;
    border-radius: 6px;
    padding: 10px;
    margin: 1rem 0;
  }
  summary {
    font-weight: bold;
    cursor: pointer;
    font-size: 1.05rem;
  }
  summary:hover {
    color: #0d47a1;
  }
</style>
</head>
<body>
  <h1>🧪 QA Automation Notes</h1>
  
  <section id="qa-terms">
  <h2>📘 Terms Every QA Professional Must Know!</h2>
  <p>If you're in QA, you should definitely know these essential terms.<br>
     They help you test better, communicate smarter, and think like a true Quality Engineer.</p>

  <details>
    <summary>🔹 1–5: Core Testing Terms</summary>
    <ul>
      <li><strong>Test Scenario</strong> – High-level condition to be tested</li>
      <li><strong>Test Case</strong> – Step-by-step instructions to verify functionality</li>
      <li><strong>Test Suite</strong> – Group of test cases for a module</li>
      <li><strong>Test Data</strong> – Input values used during testing</li>
      <li><strong>Test Plan</strong> – Strategy, scope, and schedule of testing</li>
    </ul>
  </details>

  <details>
    <summary>🔹 6–10: Requirements & Smoke Testing</summary>
    <ul>
      <li><strong>RTM</strong> – Mapping of requirements to test cases</li>
      <li><strong>Functional Testing</strong> – Validates expected functionality</li>
      <li><strong>Non-Functional Testing</strong> – Checks performance, security, usability</li>
      <li><strong>Exploratory Testing</strong> – Learning + testing without scripts</li>
      <li><strong>Smoke Testing</strong> – Basic build verification</li>
    </ul>
  </details>

  <details>
    <summary>🔹 11–15: Testing Types & Defects</summary>
    <ul>
      <li><strong>Sanity Testing</strong> – Quick checks for specific areas</li>
      <li><strong>Regression Testing</strong> – Ensure new code doesn’t break existing features</li>
      <li><strong>Retesting</strong> – Testing failed test cases after bug fix</li>
      <li><strong>Defect Life Cycle</strong> – Bug journey from open to close</li>
      <li><strong>Severity</strong> – Impact of a defect on the system</li>
    </ul>
  </details>

  <details>
    <summary>🔹 16–20: Defect Management & Validation</summary>
    <ul>
      <li><strong>Priority</strong> – Urgency of fixing the defect</li>
      <li><strong>BVA</strong> – Testing at input boundaries</li>
      <li><strong>EP</strong> – Grouping inputs into valid/invalid sets</li>
      <li><strong>UAT</strong> – End-user validation of requirements</li>
      <li><strong>QA</strong> – Process to prevent defects</li>
    </ul>
  </details>

  <details>
    <summary>🔹 21–25: Quality, Automation, DevOps</summary>
    <ul>
      <li><strong>QC</strong> – Finding defects in the product</li>
      <li><strong>Bug Leakage</strong> – Bugs missed in testing, found later</li>
      <li><strong>Bug Release</strong> – Known bugs released intentionally</li>
      <li><strong>Automation Testing</strong> – Using tools to auto-execute tests</li>
      <li><strong>CI/CD</strong> – Automated integration and deployment</li>
    </ul>
  </details>

  <details>
    <summary>🔹 26–30: Assertions, API, Performance, E2E</summary>
    <ul>
      <li><strong>Assertions</strong> – Validating expected vs actual result</li>
      <li><strong>API Testing</strong> – Testing backend using tools like Postman</li>
      <li><strong>Load Testing</strong> – Testing under expected user load</li>
      <li><strong>Integration Testing</strong> – Checking interaction between modules</li>
      <li><strong>E2E Testing</strong> – Verifying complete user flow</li>
    </ul>
  </details>

  <details>
    <summary>📋 Manual Testing Interview Questions</summary>
    <ul>
      <li><strong>1. Agile methodology:</strong> Yes, I’ve worked in Agile. It involves iterative development, daily stand-ups, sprints, backlog grooming, and reviews.</li>
      <li><strong>2. Writing test cases:</strong> Include clear steps, expected results, valid data, boundary values, and ensure they are reusable and maintainable.</li>
      <li><strong>3. Bug Life Cycle:</strong> New → Assigned → Open → Fixed → Retest → Verified → Closed (or Reopen/Rejected if needed).</li>
      <li><strong>4. Scenario vs Test Case:</strong> Scenario = High-level idea; Test Case = Step-by-step execution.</li>
      <li><strong>5. Functional vs Non-Functional:</strong> Functional checks features; Non-functional tests performance, security, etc.</li>
      <li><strong>6. Smoke vs Sanity:</strong> Smoke = basic build check; Sanity = targeted check after a fix.</li>
      <li><strong>7. STLC:</strong> Phases from Requirement Analysis → Test Planning → Test Design → Execution → Closure.</li>
      <li><strong>8. Alpha vs Beta:</strong> Alpha = in-house testing; Beta = real users before release.</li>
      <li><strong>9. Tests per sprint:</strong> Depends on complexity, usually 20–40 cases.</li>
      <li><strong>10. Automate test selection:</strong> Choose high ROI, repeatable, stable tests.</li>
      <li><strong>11. Do not automate:</strong> Exploratory, ad-hoc, or unstable UI tests.</li>
      <li><strong>12. 100% automation:</strong> Not practical or recommended.</li>
      <li><strong>13. Logging bugs:</strong> Include steps, environment, expected vs actual result, screenshots/logs.</li>
      <li><strong>14. Test case tools:</strong> Excel, TestRail, Zephyr, XRay.</li>
    </ul>
  </details>
</section>
  
  <a href="index.html">← Back to Home</a>
</body>
</html>
